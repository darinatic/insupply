{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c678834-d96d-4f01-9b03-e707260eddc0",
   "metadata": {},
   "source": [
    "**Load test data from excel into dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b795ed-1e53-45c1-b06e-679f599e9731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select the training data file:\n",
      "Top 5 rows in the training DataFrame:\n",
      "     concatenate     MM/SM no.                                Short Text  \\\n",
      "0   450000721010  3.781023e+09  (CAT 2-0) DELIVERY CHARGES APPLICABLE FO   \n",
      "1  4500007210570  3.781023e+09  (CAT 5-0) DELIVERY CHARGES APPLICABLE FO   \n",
      "2  4500007210590  3.789990e+09  (CAT 5-2B)  SOLID FIXED WALL MOUNTING <2   \n",
      "3  4500007210600  3.789990e+09  (CAT 5-2C) DOUBLE ARM SOLID WALL MOUNT <   \n",
      "4  4500007210650  3.789990e+09  (CAT 5-3B)  SOLID FIXED WALL MOUNTING <2   \n",
      "\n",
      "                              Contract Header Text  \\\n",
      "0  Supply of Electronics and Electrical Appliances   \n",
      "1  Supply of Electronics and Electrical Appliances   \n",
      "2  Supply of Electronics and Electrical Appliances   \n",
      "3  Supply of Electronics and Electrical Appliances   \n",
      "4  Supply of Electronics and Electrical Appliances   \n",
      "\n",
      "                                  Contract Item Text  \\\n",
      "0  (CAT 2-0) DELIVERY CHARGES APPLICABLE FOR PURC...   \n",
      "1  (CAT 5-0) DELIVERY CHARGES APPLICABLE FOR PURC...   \n",
      "2  (CAT 5-2B)  SOLID FIXED WALL MOUNTING <(><<)>(...   \n",
      "3  (CAT 5-2C) DOUBLE ARM SOLID WALL MOUNT <(><<)>...   \n",
      "4  (CAT 5-3B)  SOLID FIXED WALL MOUNTING <(><<)>(...   \n",
      "\n",
      "              Contract Header and Contract Item text           HTD  \\\n",
      "0  Supply of Electronics and Electrical Appliance...  WOG contract   \n",
      "1  Supply of Electronics and Electrical Appliance...  WOG contract   \n",
      "2  Supply of Electronics and Electrical Appliance...  WOG contract   \n",
      "3  Supply of Electronics and Electrical Appliance...  WOG contract   \n",
      "4  Supply of Electronics and Electrical Appliance...  WOG contract   \n",
      "\n",
      "                                     Validated GL    SM  \n",
      "0  218999 - Other Services511699 - Other Services  E043  \n",
      "1  218999 - Other Services511699 - Other Services  E043  \n",
      "2  218999 - Other Services511699 - Other Services  E043  \n",
      "3  218999 - Other Services511699 - Other Services  E043  \n",
      "4  218999 - Other Services511699 - Other Services  E043  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "# Use tkinter to select the Excel file\n",
    "def select_file():\n",
    "    Tk().withdraw()\n",
    "    file_path = askopenfilename(\n",
    "        title=\"Select Training Excel File\",\n",
    "        filetypes=[(\"Excel files\", \"*.xlsx *.xls\"), (\"All files\", \"*.*\")]\n",
    "    )\n",
    "    return file_path\n",
    "\n",
    "# Prompt the user\n",
    "print(\"Please select the training data file:\")\n",
    "training_excel_file = select_file()\n",
    "\n",
    "if training_excel_file:\n",
    "    # Read Excel file, header starts at row 2 (index 1)\n",
    "    df_training = pd.read_excel(training_excel_file, sheet_name='Unique records', header=1)\n",
    "    \n",
    "    print(\"Top 5 rows in the training DataFrame:\")\n",
    "    print(df_training.head())\n",
    "else:\n",
    "    print(\"No file selected. Please try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565b4a71-f5a1-4a3f-87ba-c1de0b503ebc",
   "metadata": {},
   "source": [
    "**Data cleansing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a147fd51-4c2d-4a25-9825-611d93623152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned training DataFrame:\n",
      "  material_number                            description  \\\n",
      "0            E043  Other Services511699 - Other Services   \n",
      "1            E043  Other Services511699 - Other Services   \n",
      "2            E043  Other Services511699 - Other Services   \n",
      "3            E043  Other Services511699 - Other Services   \n",
      "4            E043  Other Services511699 - Other Services   \n",
      "\n",
      "                                Combined Description  \n",
      "0  Supply of Electronics and Electrical Appliance...  \n",
      "1  Supply of Electronics and Electrical Appliance...  \n",
      "2  Supply of Electronics and Electrical Appliance...  \n",
      "3  Supply of Electronics and Electrical Appliance...  \n",
      "4  Supply of Electronics and Electrical Appliance...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Ensure the necessary columns exist\n",
    "required_columns = ['Contract Header and Contract Item text', 'SM', 'Validated GL']\n",
    "for col in required_columns:\n",
    "    if col not in df_training.columns:\n",
    "        raise ValueError(f\"The training Excel file must contain '{col}' column.\")\n",
    "\n",
    "# Data cleansing: Remove null values\n",
    "df_training = df_training.dropna(subset=required_columns)\n",
    "\n",
    "# Remove unwanted patterns'\n",
    "def clean_query_text(text):\n",
    "    return re.sub(r'<\\(><<\\)>(.*?)<\\(><<\\)>', '', text).strip()\n",
    "\n",
    "df_training['Contract Header and Contract Item text'] = df_training['Contract Header and Contract Item text'].apply(clean_query_text)\n",
    "\n",
    "df_training = df_training.rename(columns={\"Contract Header and Contract Item text\": \"Combined Description\"})\n",
    "df_training['material_number'] = df_training['SM'].str.strip()\n",
    "df_training['description'] = df_training['Validated GL'].str.split(' - ', n=1).str[1].str.strip()\n",
    "df_training['Combined Description'] = df_training['Combined Description'].str.strip()\n",
    "\n",
    "df_training = df_training.drop(columns=['SM', 'Validated GL'])\n",
    "\n",
    "# Display cleaned DataFrame\n",
    "print(\"\\nCleaned training DataFrame:\")\n",
    "print(df_training[['material_number', 'description', 'Combined Description']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9fe733-be85-4538-a676-dad5fe9f061f",
   "metadata": {},
   "source": [
    "**Vector embedding of materials.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9ea8ae6-23ba-4aa8-a4f7-2fa808e727ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vector embedding completed for reference data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src import search\n",
    "json_file = '../data/processed/materials.json'\n",
    "\n",
    "# Initialize the search engine with reference data\n",
    "search_engine = search.RoBERTaSearch(data_file=json_file)\n",
    "\n",
    "print(\"\\nVector embedding completed for reference data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16885247-f289-45b4-8ebc-34693700dff4",
   "metadata": {},
   "source": [
    "**Split dataframe into train test, evaluate accuracy of model against training data, export to json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db493d5-2938-4a27-8d6d-4b20775c4bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation completed. Results saved to ../data/processed/results.json\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.search import evaluate_model\n",
    "import json\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(df_training, test_size=0.9, random_state=42)\n",
    "\n",
    "# Evaluate the model on the train data\n",
    "results = evaluate_model(search_engine, train_df, top_k=5)\n",
    "\n",
    "# Save results to a JSON file for analysis\n",
    "output_file = \"../data/processed/results.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(f\"\\nEvaluation completed. Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd0d8b",
   "metadata": {},
   "source": [
    "**Generic results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b2ad01-b661-49a8-bd46-816c1e2177bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Truncate long strings\n",
    "# def truncate_text(text, max_length=30):\n",
    "#     return text if len(text) <= max_length else text[:max_length] + \"...\"\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy = sum(1 for result in results if result[\"is_correct\"]) / len(results)\n",
    "# print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# # Display evaluation results\n",
    "# print(\"\\nEvaluation Results:\")\n",
    "# for idx, result in enumerate(results[:5]):  # Display first 5 results\n",
    "#     query = truncate_text(result[\"query\"], max_length=40)\n",
    "#     expected = result[\"expected\"]\n",
    "#     correct = \"Yes\" if result[\"is_correct\"] else \"No\"\n",
    "\n",
    "#     print(f\"{idx + 1}. Query: {query}\")\n",
    "#     print(f\"   Expected: {expected}\")\n",
    "#     print(f\"   Correct: {correct}\")\n",
    "#     print(\"   Top 5 Matches:\")\n",
    "    \n",
    "#     for match in result[\"retrieved_top_5\"]:\n",
    "#         material_number = match[\"material_number\"]\n",
    "#         description = truncate_text(match[\"description\"], max_length=40)\n",
    "#         similarity_score = match[\"score\"]\n",
    "#         print(f\"      {material_number} - {description} (Score: {similarity_score:.2f}%)\")\n",
    "    \n",
    "#     print(\"-\" * 40)  # Separator between results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5794c422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional results appended to sheet 'roberta-base' in: ../data/output/evaluation_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for export\n",
    "additional_data = []\n",
    "\n",
    "# Iterate through the evaluation results\n",
    "for result in results:  # 'results' is the list of evaluation results\n",
    "    # Combine expected material number and description\n",
    "    expected_combined = f\"{result['expected']} - {result['expected_description']}\"\n",
    "\n",
    "    # Combine top 5 matched material numbers into a single string\n",
    "    top_matches_combined = \"; \".join(\n",
    "        [f\"{match['material_number']} score:{match['score']}\" for match in result[\"retrieved_top_5\"]]\n",
    "    )\n",
    "\n",
    "    additional_data.append({\n",
    "        \"query\": result[\"query\"],\n",
    "        \"expected\": expected_combined,  \n",
    "        \"matches\": top_matches_combined,  \n",
    "        \"is_correct\": \"True\" if result[\"is_correct\"] else \"False\"  \n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "additional_df = pd.DataFrame(additional_data)\n",
    "\n",
    "# Specify export path\n",
    "output_path = \"../data/output/evaluation_results.xlsx\"\n",
    "\n",
    "# Dynamically get the model name\n",
    "model_name = getattr(search_engine, \"model_name\", \"Unknown_Model\")\n",
    "sheet_name = model_name.replace(\"/\", \"_\")[:31]  \n",
    "\n",
    "# Ensure folder exists\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Append to the Excel file without overwriting existing sheets\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    additional_df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "print(f\"Additional results appended to sheet '{sheet_name}' in: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8de06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
